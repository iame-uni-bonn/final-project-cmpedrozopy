{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from geopy.distance import geodesic\n",
    "import pyreadstat\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a function to do the same that I did with the distance_df data set\n",
    "def process_distance_data(input_file, output_file):\n",
    "    \"\"\"\n",
    "    Load a CSV file, rename a column for easier merging, and save the processed data as a new CSV file.\n",
    "    \n",
    "    Args:\n",
    "        input_file (str): Path to the input CSV file.\n",
    "        output_file (str): Path to save the output CSV file.\n",
    "    \"\"\"\n",
    "    distance_df = pd.read_csv(input_file, encoding='latin1')\n",
    "    distance_df.rename(columns={'country':'mission_country'}, inplace=True)\n",
    "    distance_df.to_csv(output_file, index=False)\n",
    "\n",
    "#Apply the function to \"C:\\Users\\HP\\Desktop\\Felipe\\Moises\\Distance\\Mission_coordinatesok.csv\" and save the output to \"C:\\Users\\HP\\Desktop\\Felipe\\Moises\\Distance\\epp\\distance_to_missions_epp.csv\"\n",
    "process_distance_data(\"C:/Users/HP/Desktop/Felipe/Moises/Distance/Mission_coordinatesok.csv\", \"C:/Users/HP/Desktop/Felipe/Moises/Distance/epp/distance_to_missions_epp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_25668\\3289591575.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shape['centroid'] = shape.centroid\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_25668\\3289591575.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shape['centroid'] = shape.centroid\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_25668\\3289591575.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shape['centroid'] = shape.centroid\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_25668\\3289591575.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shape['centroid'] = shape.centroid\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_25668\\3289591575.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shape['centroid'] = shape.centroid\n"
     ]
    }
   ],
   "source": [
    "# Define the function to process shapefiles\n",
    "def shape_to_csv(department_path):\n",
    "    # Read and reproject the shp files\n",
    "    shape = gpd.read_file(department_path)\n",
    "    shape = shape.to_crs(epsg=4326)\n",
    "    # Calculate the centroid and extract the longitude and latitude\n",
    "    shape['centroid'] = shape.centroid\n",
    "    shape['longitude'] = shape['centroid'].x\n",
    "    shape['latitude'] = shape['centroid'].y\n",
    "    # Save as CSV in the same folder as the shapefile for easier access\n",
    "    output_csv = department_path.replace(\".shp\", \".csv\")\n",
    "    shape.to_csv(output_csv, index=False)\n",
    "\n",
    "# Root directory containing the folders and shapefiles\n",
    "root_dir = \"C:/Users/HP/Desktop/Felipe/Moises/Distance/shape_files\"\n",
    "\n",
    "# Go through all subdirectories and apply the function\n",
    "for root, dirs, files in os.walk(root_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\".shp\") and file.startswith(\"Distritos_\"):\n",
    "            department_path = os.path.join(root, file) \n",
    "            shape_to_csv(department_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending: C:/Users/HP/Desktop/Felipe/Moises/Distance/shape_files\\guaira_shp_data.csv\n",
      "Appending: C:/Users/HP/Desktop/Felipe/Moises/Distance/shape_files\\alto_parana\\Distritos_Alto_Parana.csv\n",
      "Appending: C:/Users/HP/Desktop/Felipe/Moises/Distance/shape_files\\caazapa\\Distritos_Caazapa.csv\n",
      "Appending: C:/Users/HP/Desktop/Felipe/Moises/Distance/shape_files\\guaira\\Distritos_Guaira.csv\n",
      "Appending: C:/Users/HP/Desktop/Felipe/Moises/Distance/shape_files\\itapua\\Distritos_Itapua.csv\n",
      "Appending: C:/Users/HP/Desktop/Felipe/Moises/Distance/shape_files\\misiones\\Distritos_Misiones.csv\n",
      "All CSV files appended and saved to: C:/Users/HP/Desktop/Felipe/Moises/Distance/epp/distritos_combined.csv\n"
     ]
    }
   ],
   "source": [
    "def append_csvs_to_one(output_file, root_dir):\n",
    "    # List to store individual DataFrames\n",
    "    all_data = []\n",
    "\n",
    "    # Walk through all subdirectories to find CSV files\n",
    "    for root, dirs, files in os.walk(root_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".csv\"):  # Process only CSV files\n",
    "                file_path = os.path.join(root, file)\n",
    "                print(f\"Appending: {file_path}\")\n",
    "                # Read the CSV and append to the list\n",
    "                df = pd.read_csv(file_path)\n",
    "                all_data.append(df)\n",
    "\n",
    "    # Concatenate all DataFrames into one\n",
    "    deparmentos_shape_ok = pd.concat(all_data, ignore_index=True)\n",
    "    # Delete duplicates in CLAVE variable\n",
    "    deparmentos_shape_ok = deparmentos_shape_ok.drop_duplicates(subset=['CLAVE'])\n",
    "\n",
    "    # Save the combined DataFrame as a single CSV\n",
    "    deparmentos_shape_ok.to_csv(output_file, index=False)\n",
    "    print(f\"All CSV files appended and saved to: {output_file}\")\n",
    "\n",
    "#Apply the function\n",
    "root_dir = \"C:/Users/HP/Desktop/Felipe/Moises/Distance/shape_files\"\n",
    "output_file = \"C:/Users/HP/Desktop/Felipe/Moises/Distance/epp/distritos_combined.csv\"\n",
    "\n",
    "append_csvs_to_one(output_file, root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closest missions have been calculated and saved!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to compute the closest mission for each department\n",
    "def find_closest_location(distritos, missions):\n",
    "    # Normalize longitude and latitude, except for rows where DPTO_DESC == 'GUAIR√Å'\n",
    "    \n",
    "\n",
    "    results = []\n",
    "\n",
    "    for index, dep in distritos.iterrows():\n",
    "        # Skip if department coordinates are invalid\n",
    "        if pd.isna(dep['latitude']) or pd.isna(dep['longitude']):\n",
    "            continue\n",
    "\n",
    "        dep_coords = (dep['latitude'], dep['longitude'])\n",
    "        \n",
    "        # Calculate distances to all missions\n",
    "        missions['distance'] = missions.apply(\n",
    "            lambda x: geodesic(dep_coords, (x['latitude'], x['longitude'])).kilometers, axis=1\n",
    "        )\n",
    "        \n",
    "        # Find the closest mission and keep the DPTO_DESC from distritos\n",
    "        closest_mission = missions.loc[missions['distance'].idxmin()]\n",
    "        results.append({\n",
    "            'department_index': index,\n",
    "            'department_code': dep.get('DPTO', 'Unknown'),\n",
    "            'department_name': dep.get('DPTO_DESC', 'Unknown'),\n",
    "            'distrito': dep.get('DIST_DESC', 'Unknown'),\n",
    "            'mission_name': closest_mission['mission_name'],\n",
    "            'mission_latitude': closest_mission['latitude'],\n",
    "            'mission_longitude': closest_mission['longitude'],\n",
    "            'distance_to_mission_km': closest_mission['distance']\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Example usage\n",
    "distritos = pd.read_csv(\"C:/Users/HP/Desktop/Felipe/Moises/Distance/epp/distritos_combined.csv\")\n",
    "missions = pd.read_csv(\"C:/Users/HP/Desktop/Felipe/Moises/Distance/epp/distance_to_missions_epp.csv\")\n",
    "\n",
    "# Compute the closest missions\n",
    "closest_missions_df = find_closest_location(distritos, missions)\n",
    "\n",
    "# Save the results\n",
    "closest_missions_df.to_csv(\"C:/Users/HP/Desktop/Felipe/Moises/Distance/closest_missions.csv\", index=False)\n",
    "\n",
    "print(\"Closest missions have been calculated and saved!\")\n",
    "\n",
    "#Now, make a function so that DIST_DESC observations are in lowercase and clean the name of the cities such that \"ascii\" characters are removed\n",
    "def clean_city_names(input_file, output_file):\n",
    "    # Load the data\n",
    "    closest_missions = pd.read_csv(input_file, encoding='latin1')\n",
    "    \n",
    "    # Lowercase the DIST_DESC column\n",
    "    closest_missions['distrito'] = closest_missions['distrito'].str.lower()\n",
    "    # Remove accents and non-ASCII characters\n",
    "    closest_missions['distrito'] = closest_missions['distrito'].apply(lambda x: unidecode(x))\n",
    "    # Later, I will merge this data set with the survey data. So, I will use a key with the cleaned city name + department code\n",
    "    # Thus, If departamento has only one digit, add a leading zero. Also, make department_code string first\n",
    "    #closest_missions['department_code'] = closest_missions['department_code'].astype(str)\n",
    "    #closest_missions['department_code'] = closest_missions['department_code'].apply(lambda x: f\"0{x}\" if len(str(x)) == 1 else x)\n",
    "\n",
    "    # Save the cleaned data\n",
    "    closest_missions.to_csv(output_file, index=False, encoding='latin1')\n",
    "    # Remove non-ASCII characters from the distrito column\n",
    "   # closest_missions['distrito'] = closest_missions['distrito'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "    # Save the cleaned data\n",
    "    #closest_missions.to_csv(output_file, index=False)\n",
    "#Apply the function to \"C:/Users/HP/Desktop/Felipe/Moises/Distance/closest_missions.csv\" and save the output to \"C:/Users/HP/Desktop/Felipe/Moises/Distance/epp/closest_missions_cleaned.csv\"\n",
    "clean_city_names(\"C:/Users/HP/Desktop/Felipe/Moises/Distance/closest_missions.csv\", \"C:/Users/HP/Desktop/Felipe/Moises/Distance/epp/closest_missions_cleaned.csv\")\n",
    "\n",
    "#Now, generate a key to merge closest_missions_cleaned with survey data later.\n",
    "#The key should be the cleaned city name + department code\n",
    "#Hence, first geberate a function such that If departamento has only one digit, add a leading zero\n",
    "def add_leading_zero(x):\n",
    "    \"\"\"\n",
    "    Add a leading zero to single-digit department codes.\n",
    "    \n",
    "    Args:\n",
    "        x (int or str): The department code.\n",
    "    \n",
    "    Returns:\n",
    "        str: The department code with a leading zero if necessary.\n",
    "    \"\"\"\n",
    "    # Convert to string\n",
    "    x = str(x)\n",
    "    # Check if the length is 1\n",
    "    if len(x) == 1:\n",
    "        return f\"0{x}\"\n",
    "    return x\n",
    "\n",
    "#Now, apply the function to the department_code column of \"C:/Users/HP/Desktop/Felipe/Moises/Distance/epp/closest_missions_cleaned.csv\"\n",
    "closest_missions = pd.read_csv(\"C:/Users/HP/Desktop/Felipe/Moises/Distance/epp/closest_missions_cleaned.csv\", encoding='latin1')\n",
    "closest_missions['department_code'] = closest_missions['department_code'].apply(add_leading_zero)\n",
    "\n",
    "#Finally, generate the key\n",
    "closest_missions['key'] = closest_missions['distrito'] + closest_missions['department_code']\n",
    "#Save the data\n",
    "closest_missions.to_csv(\"C:/Users/HP/Desktop/Felipe/Moises/Distance/epp/closest_missions_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a function to read the survey data\n",
    "def process_survey_data(input_file, output_file):\n",
    "    # Read the .dta file using pyreadstat\n",
    "    survey_data, metadata = pyreadstat.read_dta(input_file)\n",
    "    # Replace the codes in 'distrito' with their corresponding labels\n",
    "    distrito_labels = metadata.value_labels[metadata.variable_to_label['distrito']]\n",
    "    survey_data['distrito'] = survey_data['distrito'].map(distrito_labels)\n",
    "    # If departamento has only one digit, add a leading zero\n",
    "    survey_data['departamento'] = survey_data['departamento'].apply(lambda x: f\"0{x}\" if len(str(x)) == 1 else x)\n",
    "    # Remove accents and non-ASCII characters\n",
    "    survey_data['distrito'] = survey_data['distrito'].apply(lambda x: unidecode(x))\n",
    "    # Save the cleaned data\n",
    "    survey_data.to_csv(output_file, index=False, encoding='latin1')\n",
    "\n",
    "#Apply the function to the survey_data\n",
    "survey_data = process_survey_data(\"C:/Users/HP/Desktop/Felipe/Encuesta/survey_final.dta\", \"C:/Users/HP/Desktop/Felipe/Moises/Distance/epp/survey_data_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Define a function to generate a key for the survey data so I can merge later with the closest_missions data\n",
    "def generate_key(survey_data):\n",
    "    #Create a new column 'key' that combines 'distrito' and dptocode\n",
    "    survey_data['key'] = survey_data['distrito'] + survey_data['departamento'].astype(str)\n",
    "\n",
    "#Apply the function to the survey data\n",
    "survey_data = pd.read_csv(\"C:/Users/HP/Desktop/Felipe/Moises/Distance/epp/survey_data_cleaned.csv\", encoding='latin1')\n",
    "generate_key(survey_data)\n",
    "#Save the data\n",
    "survey_data.to_csv(\"C:/Users/HP/Desktop/Felipe/Moises/Distance/epp/survey_data_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, merge the survey data with the closest_missions data\n",
    "#First, load the survey data\n",
    "survey_data = pd.read_csv(\"C:/Users/HP/Desktop/Felipe/Moises/Distance/epp/survey_data_cleaned.csv\", encoding='latin1')\n",
    "#Load the closest_missions data\n",
    "closest_missions = pd.read_csv(\"C:/Users/HP/Desktop/Felipe/Moises/Distance/epp/closest_missions_cleaned.csv\", encoding='latin1')\n",
    "#Merge the two data sets\n",
    "merged_data = pd.merge(survey_data, closest_missions, on='key', how='left')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_mp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
