{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from geopy.distance import geodesic\n",
    "import pyreadstat\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pytask\n",
    "\n",
    "from project_mp.config import BLD, SRC\n",
    "from project_mp.data_management.process_distance_data import (\n",
    "    process_distance_data,\n",
    ")\n",
    "\n",
    "def task_process_distance_data(\n",
    "        data_path = SRC / \"data\" / \"Mission_coordinatesok.csv\",\n",
    "        produces = BLD / \"data\" / \"distance_to_missions.pickle\",\n",
    "):\n",
    "    \"\"\"Clean the distance data set.\"\"\"\n",
    "    process_distance_data(data_path, produces)\n",
    "    processed_data = pd.read_csv(produces, encoding='latin1')\n",
    "    processed_data.to_pickle(produces)\n",
    "\n",
    "#apply the function to the data\n",
    "task_process_distance_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a function to do the same that I did with the distance_df data set\n",
    "def process_distance_data(input_file, output_file):\n",
    "    \"\"\"\n",
    "    Load a CSV file, rename a column for easier merging, and save the processed data as a new CSV file.\n",
    "    \n",
    "    Args:\n",
    "        input_file (str): Path to the input CSV file.\n",
    "        output_file (str): Path to save the output CSV file.\n",
    "    \"\"\"\n",
    "    distance_df = pd.read_csv(input_file, encoding='latin1')\n",
    "    distance_df.rename(columns={'country':'mission_country'}, inplace=True)\n",
    "    distance_df.to_csv(output_file, index=False)\n",
    "\n",
    "#Apply the function to \"C:\\Users\\HP\\Desktop\\Felipe\\Moises\\Distance\\Mission_coordinatesok.csv\" and save the output to \"C:\\Users\\HP\\Desktop\\Felipe\\Moises\\Distance\\epp\\distance_to_missions_epp.csv\"\n",
    "process_distance_data(\"C:/Users/HP/Desktop/Felipe/Moises/Distance/Mission_coordinatesok.csv\", \"C:/Users/HP/Desktop/Felipe/Moises/Distance/epp/distance_to_missions_epp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_25668\\3289591575.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shape['centroid'] = shape.centroid\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_25668\\3289591575.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shape['centroid'] = shape.centroid\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_25668\\3289591575.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shape['centroid'] = shape.centroid\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_25668\\3289591575.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shape['centroid'] = shape.centroid\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_25668\\3289591575.py:7: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  shape['centroid'] = shape.centroid\n"
     ]
    }
   ],
   "source": [
    "# Define the function to process shapefiles\n",
    "def shape_to_csv(department_path):\n",
    "    # Read and reproject the shp files\n",
    "    shape = gpd.read_file(department_path)\n",
    "    shape = shape.to_crs(epsg=4326)\n",
    "    # Calculate the centroid and extract the longitude and latitude\n",
    "    shape['centroid'] = shape.centroid\n",
    "    shape['longitude'] = shape['centroid'].x\n",
    "    shape['latitude'] = shape['centroid'].y\n",
    "    # Save as CSV in the same folder as the shapefile for easier access\n",
    "    output_csv = department_path.replace(\".shp\", \".csv\")\n",
    "    shape.to_csv(output_csv, index=False)\n",
    "\n",
    "# Root directory containing the folders and shapefiles\n",
    "root_dir = \"C:/Users/HP/Desktop/Felipe/Moises/Distance/shape_files\"\n",
    "\n",
    "# Go through all subdirectories and apply the function\n",
    "for root, dirs, files in os.walk(root_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\".shp\") and file.startswith(\"Distritos_\"):\n",
    "            department_path = os.path.join(root, file) \n",
    "            shape_to_csv(department_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending: C:/Users/HP/Desktop/Felipe/Moises/Distance/shape_files\\guaira_shp_data.csv\n",
      "Appending: C:/Users/HP/Desktop/Felipe/Moises/Distance/shape_files\\alto_parana\\Distritos_Alto_Parana.csv\n",
      "Appending: C:/Users/HP/Desktop/Felipe/Moises/Distance/shape_files\\caazapa\\Distritos_Caazapa.csv\n",
      "Appending: C:/Users/HP/Desktop/Felipe/Moises/Distance/shape_files\\guaira\\Distritos_Guaira.csv\n",
      "Appending: C:/Users/HP/Desktop/Felipe/Moises/Distance/shape_files\\itapua\\Distritos_Itapua.csv\n",
      "Appending: C:/Users/HP/Desktop/Felipe/Moises/Distance/shape_files\\misiones\\Distritos_Misiones.csv\n",
      "All CSV files appended and saved to: C:/Users/HP/Desktop/Felipe/Moises/Distance/epp/distritos_combined.csv\n"
     ]
    }
   ],
   "source": [
    "def append_csvs_to_one(output_file, root_dir):\n",
    "    # List to store individual DataFrames\n",
    "    all_data = []\n",
    "\n",
    "    # Walk through all subdirectories to find CSV files\n",
    "    for root, dirs, files in os.walk(root_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".csv\"):  # Process only CSV files\n",
    "                file_path = os.path.join(root, file)\n",
    "                print(f\"Appending: {file_path}\")\n",
    "                # Read the CSV and append to the list\n",
    "                df = pd.read_csv(file_path)\n",
    "                all_data.append(df)\n",
    "\n",
    "    # Concatenate all DataFrames into one\n",
    "    deparmentos_shape_ok = pd.concat(all_data, ignore_index=True)\n",
    "    # Delete duplicates in CLAVE variable\n",
    "    deparmentos_shape_ok = deparmentos_shape_ok.drop_duplicates(subset=['CLAVE'])\n",
    "\n",
    "    # Save the combined DataFrame as a single CSV\n",
    "    deparmentos_shape_ok.to_csv(output_file, index=False)\n",
    "    print(f\"All CSV files appended and saved to: {output_file}\")\n",
    "\n",
    "#Apply the function\n",
    "root_dir = \"C:/Users/HP/Desktop/Felipe/Moises/Distance/shape_files\"\n",
    "output_file = \"C:/Users/HP/Desktop/Felipe/Moises/Distance/epp/distritos_combined.csv\"\n",
    "\n",
    "append_csvs_to_one(output_file, root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closest missions have been calculated and saved!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to compute the closest mission for each department\n",
    "def find_closest_location(distritos, missions):\n",
    "    # Normalize longitude and latitude, except for rows where DPTO_DESC == 'GUAIR√Å'\n",
    "    \n",
    "\n",
    "    results = []\n",
    "\n",
    "    for index, dep in distritos.iterrows():\n",
    "        # Skip if department coordinates are invalid\n",
    "        if pd.isna(dep['latitude']) or pd.isna(dep['longitude']):\n",
    "            continue\n",
    "\n",
    "        dep_coords = (dep['latitude'], dep['longitude'])\n",
    "        \n",
    "        # Calculate distances to all missions\n",
    "        missions['distance'] = missions.apply(\n",
    "            lambda x: geodesic(dep_coords, (x['latitude'], x['longitude'])).kilometers, axis=1\n",
    "        )\n",
    "        \n",
    "        # Find the closest mission and keep the DPTO_DESC from distritos\n",
    "        closest_mission = missions.loc[missions['distance'].idxmin()]\n",
    "        results.append({\n",
    "            'department_index': index,\n",
    "            'department_code': dep.get('DPTO', 'Unknown'),\n",
    "            'department_name': dep.get('DPTO_DESC', 'Unknown'),\n",
    "            'distrito': dep.get('DIST_DESC', 'Unknown'),\n",
    "            'mission_name': closest_mission['mission_name'],\n",
    "            'mission_latitude': closest_mission['latitude'],\n",
    "            'mission_longitude': closest_mission['longitude'],\n",
    "            'distance_to_mission_km': closest_mission['distance']\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Example usage\n",
    "distritos = pd.read_csv(\"C:/Users/HP/Desktop/Felipe/Moises/Distance/epp/distritos_combined.csv\")\n",
    "missions = pd.read_csv(\"C:/Users/HP/Desktop/Felipe/Moises/Distance/epp/distance_to_missions_epp.csv\")\n",
    "\n",
    "# Compute the closest missions\n",
    "closest_missions_df = find_closest_location(distritos, missions)\n",
    "\n",
    "# Save the results\n",
    "closest_missions_df.to_csv(\"C:/Users/HP/Desktop/Felipe/Moises/Distance/closest_missions.csv\", index=False)\n",
    "\n",
    "print(\"Closest missions have been calculated and saved!\")\n",
    "\n",
    "#Now, make a function so that DIST_DESC observations are in lowercase and clean the name of the cities such that \"ascii\" characters are removed\n",
    "def clean_city_names(input_file, output_file):\n",
    "    # Load the data\n",
    "    closest_missions = pd.read_csv(input_file, encoding='latin1')\n",
    "    \n",
    "    # Lowercase the DIST_DESC column\n",
    "    closest_missions['distrito'] = closest_missions['distrito'].str.lower()\n",
    "    # Remove accents and non-ASCII characters\n",
    "    closest_missions['distrito'] = closest_missions['distrito'].apply(lambda x: unidecode(x))\n",
    "    # Later, I will merge this data set with the survey data. So, I will use a key with the cleaned city name + department code\n",
    "    # Thus, If departamento has only one digit, add a leading zero. Also, make department_code string first\n",
    "    #closest_missions['department_code'] = closest_missions['department_code'].astype(str)\n",
    "    #closest_missions['department_code'] = closest_missions['department_code'].apply(lambda x: f\"0{x}\" if len(str(x)) == 1 else x)\n",
    "\n",
    "    # Save the cleaned data\n",
    "    closest_missions.to_csv(output_file, index=False, encoding='latin1')\n",
    "    # Remove non-ASCII characters from the distrito column\n",
    "   # closest_missions['distrito'] = closest_missions['distrito'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "    # Save the cleaned data\n",
    "    #closest_missions.to_csv(output_file, index=False)\n",
    "#Apply the function to \"C:/Users/HP/Desktop/Felipe/Moises/Distance/closest_missions.csv\" and save the output to \"C:/Users/HP/Desktop/Felipe/Moises/Distance/epp/closest_missions_cleaned.csv\"\n",
    "clean_city_names(\"C:/Users/HP/Desktop/Felipe/Moises/Distance/closest_missions.csv\", \"C:/Users/HP/Desktop/Felipe/Moises/Distance/epp/closest_missions_cleaned.csv\")\n",
    "\n",
    "#Now, generate a key to merge closest_missions_cleaned with survey data later.\n",
    "#The key should be the cleaned city name + department code\n",
    "#Hence, first geberate a function such that If departamento has only one digit, add a leading zero\n",
    "def add_leading_zero(x):\n",
    "    \"\"\"\n",
    "    Add a leading zero to single-digit department codes.\n",
    "    \n",
    "    Args:\n",
    "        x (int or str): The department code.\n",
    "    \n",
    "    Returns:\n",
    "        str: The department code with a leading zero if necessary.\n",
    "    \"\"\"\n",
    "    # Convert to string\n",
    "    x = str(x)\n",
    "    # Check if the length is 1\n",
    "    if len(x) == 1:\n",
    "        return f\"0{x}\"\n",
    "    return x\n",
    "\n",
    "#Now, apply the function to the department_code column of \"C:/Users/HP/Desktop/Felipe/Moises/Distance/epp/closest_missions_cleaned.csv\"\n",
    "closest_missions = pd.read_csv(\"C:/Users/HP/Desktop/Felipe/Moises/Distance/epp/closest_missions_cleaned.csv\", encoding='latin1')\n",
    "closest_missions['department_code'] = closest_missions['department_code'].apply(add_leading_zero)\n",
    "\n",
    "#Needs a function to generate the key\n",
    "#Finally, generate the key\n",
    "def generate_key(closest_missions):\n",
    "    \"\"\"\n",
    "    Generate a key for merging the closest missions data with survey data.\n",
    "    \n",
    "    Args:\n",
    "        closest_missions (pd.DataFrame): The closest missions data.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: The closest missions data with a key column.\n",
    "    \"\"\"\n",
    "    # Generate the key\n",
    "    closest_missions['key'] = closest_missions['distrito'] + closest_missions['department_code']\n",
    "    return closest_missions\n",
    "\n",
    "#Save the data\n",
    "generate_key(closest_missions).to_csv(\"C:/Users/HP/Desktop/Felipe/Moises/Distance/epp/closest_missions_cleaned.csv\", index=False, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before leading zero fix: [10  8  4  6  7]\n",
      "After leading zero fix: ['10' '08' '04' '06' '07']\n",
      "   nro_cuestionario  tipo_formulario  departamento           distrito  \\\n",
      "0              1241                1            10       hernandarias   \n",
      "1              1265                2             8  san juan bautista   \n",
      "2              1042                1             4               Numi   \n",
      "3              1089                2             8         san miguel   \n",
      "4              1127                2             8         san miguel   \n",
      "\n",
      "   localidad          s          o  altitud  gps_nro  fecha_entrevista_dia  \\\n",
      "0        564 -25.410032 -54.645100    227.0       21                    27   \n",
      "1        550 -26.674168 -57.145817    136.0       21                    23   \n",
      "2        517 -25.954933 -56.329567    139.0       12                    18   \n",
      "3        531 -26.536833 -57.043083    124.0       21                    17   \n",
      "4        507 -26.532932 -57.042450    132.0       22                    17   \n",
      "\n",
      "   ...  cheating2  rotter1  rotter2  rotter4  rotter5  rotter9  rotter  \\\n",
      "0  ...        1.0      5.0      4.0      4.0      4.0      4.0    33.0   \n",
      "1  ...        0.0      4.0      3.0      4.0      4.0      3.0    34.0   \n",
      "2  ...        1.0      5.0      4.0      4.0      4.0      2.0    34.0   \n",
      "3  ...        1.0      5.0      4.0      5.0      5.0      1.0    41.0   \n",
      "4  ...        0.0      4.0      4.0      4.0      4.0      4.0    35.0   \n",
      "\n",
      "   treatprime male  desirability  \n",
      "0         0.0  0.0     -0.300753  \n",
      "1         0.0  0.0     -0.300753  \n",
      "2         0.0  0.0     -0.300753  \n",
      "3         0.0  0.0     -0.300753  \n",
      "4         0.0  0.0     -0.300753  \n",
      "\n",
      "[5 rows x 211 columns]\n"
     ]
    }
   ],
   "source": [
    "#Define a function to read the survey data\n",
    "def process_survey_data(input_file, output_file):\n",
    "    # Read the .dta file using pyreadstat\n",
    "    survey_data, metadata = pyreadstat.read_dta(input_file)\n",
    "    # Replace the codes in 'distrito' with their corresponding labels\n",
    "    distrito_labels = metadata.value_labels[metadata.variable_to_label['distrito']]\n",
    "    survey_data['distrito'] = survey_data['distrito'].map(distrito_labels)\n",
    "    #Make departamento variable string\n",
    "    print(\"Before leading zero fix:\", survey_data['departamento'].unique())\n",
    "    survey_data['departamento'] = survey_data['departamento'].astype(str)\n",
    "    # If departamento has only one digit, add a leading zero\n",
    "    survey_data['departamento'] = survey_data['departamento'].apply(\n",
    "    lambda x: x.zfill(2) if x.isdigit() else x\n",
    "    )\n",
    "    print(\"After leading zero fix:\", survey_data['departamento'].unique())\n",
    "    # Remove accents and non-ASCII characters\n",
    "    survey_data['distrito'] = survey_data['distrito'].apply(lambda x: unidecode(x))\n",
    "    # Save the cleaned data\n",
    "    survey_data.to_csv(output_file, index=False, encoding='latin1')\n",
    "    # Return the cleaned data\n",
    "    return survey_data\n",
    "\n",
    "#Apply the function to the survey_data\n",
    "survey_data = process_survey_data(\"C:/Users/HP/Desktop/Felipe/Encuesta/survey_final.dta\", \"C:/Users/HP/Desktop/Felipe/Moises/Distance/epp/survey_data_cleaned.csv\")\n",
    "\n",
    "#Save the data\n",
    "survey_data_cleaned = pd.read_csv(\n",
    "    \"C:/Users/HP/Desktop/Felipe/Moises/Distance/epp/survey_data_cleaned.csv\", \n",
    "    encoding='latin1'\n",
    ")\n",
    "\n",
    "print(survey_data_cleaned.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before processing 'departamento': [10  8  4  6  7]\n",
      "After processing 'departamento': ['10' '08' '04' '06' '07']\n"
     ]
    }
   ],
   "source": [
    "# Define a function to process survey data\n",
    "def process_survey_data(input_file, output_file):\n",
    "    # Read the .dta file using pyreadstat\n",
    "    survey_data, metadata = pyreadstat.read_dta(input_file)\n",
    "    \n",
    "    # Replace the codes in 'distrito' with their corresponding labels\n",
    "    distrito_labels = metadata.value_labels[metadata.variable_to_label['distrito']]\n",
    "    survey_data['distrito'] = survey_data['distrito'].map(distrito_labels)\n",
    "    \n",
    "    # Debug: Inspect 'departamento' before processing\n",
    "    print(\"Before processing 'departamento':\", survey_data['departamento'].unique())\n",
    "    \n",
    "    # Ensure 'departamento' is a string and strip whitespace\n",
    "    survey_data['departamento'] = survey_data['departamento'].astype(str).str.strip()\n",
    "    \n",
    "    # Add a leading zero if 'departamento' has only one digit\n",
    "    survey_data['departamento'] = survey_data['departamento'].apply(\n",
    "    lambda x: x.zfill(2) if x.isdigit() else x\n",
    "    )\n",
    "    \n",
    "    # Debug: Inspect 'departamento' after processing\n",
    "    print(\"After processing 'departamento':\", survey_data['departamento'].unique())\n",
    "    \n",
    "    # Remove accents and non-ASCII characters from 'distrito'\n",
    "    survey_data['distrito'] = survey_data['distrito'].apply(lambda x: unidecode(x) if isinstance(x, str) else x)\n",
    "    \n",
    "    # Save the cleaned data\n",
    "    survey_data.to_csv(output_file, index=False, encoding='latin1')\n",
    "    \n",
    "    # Return the cleaned DataFrame\n",
    "    return survey_data\n",
    "\n",
    "# Apply the function to the survey data\n",
    "survey_data = process_survey_data(\n",
    "    \"C:/Users/HP/Desktop/Felipe/Encuesta/survey_final.dta\", \n",
    "    \"C:/Users/HP/Desktop/Felipe/Moises/Distance/epp/survey_data_cleaned.csv\"\n",
    ")\n",
    "\n",
    "# Load the saved data to confirm it's cleaned\n",
    "#survey_data_cleaned = pd.read_excel(\"survey_data_cleaned.xlsx\")\n",
    "#print(survey_data_cleaned.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Define a function to generate a key for the survey data so I can merge later with the closest_missions data\n",
    "def generate_key(survey_data):\n",
    "    #Create a new column 'key' that combines 'distrito' and dptocode\n",
    "    survey_data['key'] = survey_data['distrito'] + survey_data['departamento'].astype(str)\n",
    "\n",
    "#Apply the function to the survey data\n",
    "survey_data = pd.read_csv(\"C:/Users/HP/Desktop/Felipe/Moises/Distance/epp/survey_data_cleaned.csv\", encoding='latin1')\n",
    "generate_key(survey_data)\n",
    "#Save the data\n",
    "survey_data.to_csv(\"C:/Users/HP/Desktop/Felipe/Moises/Distance/epp/survey_data_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded survey data with 560 rows.\n",
      "Loaded closest missions data with 91 rows.\n",
      "Merged data contains 560 rows.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def merge_survey_and_missions(survey_file, missions_file, key_column):\n",
    "    \"\"\"\n",
    "    Loads survey data and closest missions data, then merges them on the specified key column.\n",
    "\n",
    "    Parameters:\n",
    "    - survey_file (str): Path to the survey data CSV file.\n",
    "    - missions_file (str): Path to the closest missions data CSV file.\n",
    "    - key_column (str): Column name to merge on.\n",
    "    - encoding (str): Encoding of the CSV files (default is 'latin1').\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Merged DataFrame.\n",
    "    \"\"\"        \n",
    "    # Load the survey data\n",
    "    survey_data = pd.read_csv(survey_file)\n",
    "    print(f\"Loaded survey data with {len(survey_data)} rows.\")\n",
    "\n",
    "    # Load the closest missions data\n",
    "    closest_missions = pd.read_csv(missions_file)\n",
    "    print(f\"Loaded closest missions data with {len(closest_missions)} rows.\")\n",
    "\n",
    "    # Merge the two data sets on the key column\n",
    "    merged_data = pd.merge(survey_data, closest_missions, on=key_column, how='left')\n",
    "    print(f\"Merged data contains {len(merged_data)} rows.\")\n",
    "    # Save the merged data\n",
    "    merged_data.to_csv(\"C:/Users/HP/Desktop/Felipe/Moises/Distance/epp/survey_with_missions.csv\", index=False)\n",
    "\n",
    "survey_file = \"C:/Users/HP/Desktop/Felipe/Moises/Distance/epp/survey_data_cleaned.csv\"\n",
    "missions_file = \"C:/Users/HP/Desktop/Felipe/Moises/Distance/epp/closest_missions_cleaned.csv\"\n",
    "#Apply the function to the survey data and closest_missions data\n",
    "merge_survey_and_missions(\"C:/Users/HP/Desktop/Felipe/Moises/Distance/epp/survey_data_cleaned.csv\", \"C:/Users/HP/Desktop/Felipe/Moises/Distance/epp/closest_missions_cleaned.csv\", \"key\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_mp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
